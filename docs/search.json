[
  {
    "objectID": "submissions.html",
    "href": "submissions.html",
    "title": "Submissions",
    "section": "",
    "text": "Replication Research is a publication platform for replications and replications from various disciplines. Articles need to disclose what original study and hypothesis/claim they replicated or reproduced. For an up-to-date overview of the disciplines from which we accept submissions, please see the editorial board. Generally, we can provide adequate quality assurance and peer-review for cognitive, behavioral, and social science studies (psychology, economics, sociology, education sciences, political sciences).\nPlease note that the entire review process is open and reviews will be permanently linked with submitted manuscripts via their DOIs and Pubpeer.com regardless whether the article is accepted or rejected. This is so that quality assurance is transparent, and so that work provided by reviewers for Replication Research is credited and not discarded."
  },
  {
    "objectID": "submissions.html#submission-preparation-checklist",
    "href": "submissions.html#submission-preparation-checklist",
    "title": "Submissions",
    "section": "Submission Preparation Checklist",
    "text": "Submission Preparation Checklist\n\nPre-print uploaded to repository and assigned a DOI\nPreregistration link accessible and included in manuscript\nPreregistration deviations disclosed and discussed\nOpen Data, Materials, and Code accessible and linked in the manuscript\nInstructions for push-button-replications provided and linked in the manuscript"
  },
  {
    "objectID": "submissions.html#author-guidelines",
    "href": "submissions.html#author-guidelines",
    "title": "Submissions",
    "section": "Author Guidelines",
    "text": "Author Guidelines\n\nPre-Submission checks\nAuthors need to conduct automatized checks before submission. These include checks of reported test statistics and p-values via statcheck.io, checks for non-cited replication studies via FReD Annotator, and checks for cited retracted articles via Papercheck (Scienceverse).\nPre-Prints\nBefore submission, articles must be posted to a pre-print server that assigns the article a DOI (e.g., arXiv, OSF preprints, Zenodo).\nPreregistration\nStudies must be preregistered. Exceptions need to be justified and clearly communicated as exploratory studies. The link to the preregistration must be included in the manuscript and accessible during peer review. The authors must disclose whether the analysis plan was included in the preregistration and whether the analysis script was preregistered. All deviations from the preregistration must be discussed openly with respect to (1) a description of the deviation, (2) a justification for it, and (3) a note on how the deviation does or might affect the results.\nOpen Data, Materials, and Code\nData, materials, and code must be posted to a trusted repository (e.g., osf.io, researchbox.org, zenodo.org). Links to the repository must be included in the manuscript. Upon acceptance, the authors must create a frozen version of the repository and update all links (e.g., via OSF Registrations). Exceptions must be identified and justified at article submission (e.g., ethical reasons).\nTransparency Statement\nAuthors must declare all potential conflicts of interest, include the 21 word solution or a derivative thereof, and explain if and how they are connected to the authors of the original work. Authors must declare use of AI (e.g., “The introduction has been written by ChatGTP 4.0”).\nReproducibility\nResults need to be push-button-replicable. That means, the authors need to provide simple instructions on how to reproduce all results reported in the manuscript. To facilitate reproducibility checks, we encourage authors to use free open source software. A link to the instructions needs to be included in the manuscript.\nPubPeer commenting\nRegardless of the decision (accept, revise, reject), reviews and responses will be posted to PubPeer (pubpeer.com) after each stage.\nCollaborative Copy-Editing\nReplication Research has no author processing charges. To be able to maintain the journal, authors are expected to engage in copy-editing. Consequently, this phase will take as long as a peer-review round."
  },
  {
    "objectID": "submissions.html#article-types",
    "href": "submissions.html#article-types",
    "title": "Submissions",
    "section": "Article Types",
    "text": "Article Types\nAll articles submitted to Replication Research need to investigate a research question that has been previously investigated in a published study. These can be computational reproductions using the same data and code, robustness checks using the same data but different procedures, close replications using new data and the same method, or conceptual replications using new data and a different method. Replication closeness needs to be described in detail.\n\nReplications (different data)\nReplication studies can be internal (i.e., by the same group of researchers), close, or conceptual (for a typology see Hüffmeier et al., 2016). Authors can use their own format or a standardized template provided by Replication Research. This Standardized Replication Template (StaRT) is available online at https://osf.io/3jgxd.\nUpon acceptance, we expect authors to enter their replication study in to the FORRT Replication Database (if it is not included yet).\n\n\nReproductions (same data)\nFor reproductions (i.e., studies where no new data is collected), we recommend the use of the Institute4Replication’s template available via this OSF Project. We do not accept reproductions with overlapping authorship.\n\n\nMultiverse Analyses and Many Analyst Studies\nThere are many paths from raw data to results. Approaches that aim to wander most or all of them are called multiverse analyses, approaches to have many people choose their preferred path are called Multi Analys Studies. Both contain information about the robustness or generalizability and are thus an integral part of repetitive research.\n\n\nMulti-study articles\nFor multi-study articles, a mix of replications and reproductions is possible. If possible, authors should conduct a mini meta-analysis. Authors need to disclose for each study whether it is a replication or reproduction. A mix of original studies and replication is not possible.\n\n\nStudent Reports\nArticles whose first authors are enrolled at a university at the time of submission can be submitted as Student Report. Submissions need to include a certificate of enrollment at a university for the first author. None of the other authors need to be students. Supervisors do not need to be included as authors but need to be mentioned in the manuscript. Review for student reports is aimed to be faster (two weeks deadline for one review instead of four weeks for two independent reviews). Quality standards are as high as non-student reports with the exception that low-powered replications may be accepted if they discuss the limitations and provide useful new information such as reproduced materials or analysis plans that are not clear from original reports. Reviews are still open and articles need to adhere to submission guidelines and TOP guidelines. Please note that students can also submit their articles as non-student reports.\n\n\nRegistered Reports\nReplication Research accepts registered reports for studies where new data is collected. More information on registered repots is available in the template guide provided by the OSF."
  },
  {
    "objectID": "submissions.html#badges",
    "href": "submissions.html#badges",
    "title": "Submissions",
    "section": "Badges",
    "text": "Badges\nFor articles meeting the requirements listed in the Author Guidelines, we assign the following badges (images provided by OSF):"
  },
  {
    "objectID": "submissions.html#contributions-and-references",
    "href": "submissions.html#contributions-and-references",
    "title": "Submissions",
    "section": "Contributions and References",
    "text": "Contributions and References\nThese guidelines are shared under a CC 4.0 by Attribution License and have been created by Lukas Röseler (Writing - first draft) and XXX (CRediT). They are loosely based on the submission guidelines from Meta Psychology (https://open.lnu.se/index.php/metapsychology/about/submissions)."
  },
  {
    "objectID": "Issues.html",
    "href": "Issues.html",
    "title": "Issues",
    "section": "",
    "text": "Submissions are not open yet. We plan to launch the journal in late 2025."
  },
  {
    "objectID": "editorialteam.html",
    "href": "editorialteam.html",
    "title": "Editorial Team",
    "section": "",
    "text": "Person\nRole\n\n\nNAME\nJournal Manager\n\n\nNAME\nEditor-in-Chief\n\n\nMüCOS Research Assistant\nEditorial Assistant\n\n\nNAME\nEditorial Board, Psychology\n\n\nNAME\nEditorial Board, Medicine\n\n\nNAME\nEditorial Board, Biology\n\n\nNAME\nEditorial Board, Political Sciences\n\n\nNAME\nEditorial Board, Education Sciences\n\n\nNAME\nAction Editor\n\n\nNAME\nAdvisory Board\n\n\nMüCOS Research Assistant\nReproducibility Manager\n\n\nNAME\nReproducibility Team\n\n\nNAME\nReproducibility Team\n\n\n\n\nEditorial Members’ Conflict of Interest\nFor the foundation of Replication Research, we gathered experts on replication research from various disciplines. At the same time, replication research is conducted and published only rarely. This might lead to potential conflicts of interests, where members of the editorial team or their close colleagues submit research articles. For this reason, we require reviewers to disclose whether they have been working together with the author / one of the authors or with the handling editor.\n\n\n\n\n\n\nReplication Research Network\n\n\n\nIn summer 2024, an international network of researchers has finalized a research proposal for the foundation of a publication platform for replication research. This journal concept is embedded into this. The proposal is openly available:\nRöseler, L. (2024). Research Proposal: Replication Journal (Topical Program). Retrieved from https://osf.io/p4dzb\nPlease get in touch if you are interested in supporting this endeavour or if you would like to keep updated on it."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About the Journal",
    "section": "",
    "text": "Replication Research (R2) is an interdisciplinary journal for replication research. This includes reproductions, where the same code and data are used to verify the originally reported results, close replications, where new data is collected with a method closely resembling an original study, or conceptual replications, where a previously tested hypothesis is re-tested using new methods and new data. We currently accept replications from the social, cognitive, and behavioral sciences as well as medicine."
  },
  {
    "objectID": "about.html#diamond-open-access-without-processing-fees",
    "href": "about.html#diamond-open-access-without-processing-fees",
    "title": "About the Journal",
    "section": "Diamond Open Access without Processing Fees",
    "text": "Diamond Open Access without Processing Fees\nReplication Research is a researcher-led journal that is and will forever be free to read and to publish (Diamond Open Access, no Author Processing Charges)."
  },
  {
    "objectID": "about.html#truly-open-peer-review",
    "href": "about.html#truly-open-peer-review",
    "title": "About the Journal",
    "section": "Truly Open Peer Review",
    "text": "Truly Open Peer Review\nAll reviews are published after each round of peer-review, that is, regardless whether the manuscript is accepted or rejected for publication."
  },
  {
    "objectID": "about.html#reproducibility",
    "href": "about.html#reproducibility",
    "title": "About the Journal",
    "section": "Reproducibility",
    "text": "Reproducibility\nBefore publication, reproducibility checks are conducted for the reported results. Articles are not published unless these reproducibility checks are successful. This process is overseen by the reproducibility manager"
  },
  {
    "objectID": "about.html#article-types",
    "href": "about.html#article-types",
    "title": "About the Journal",
    "section": "Article Types",
    "text": "Article Types\nReplication Research accepts submissions that include reproducibility checks (including multiverse analyses and many analyst studies), internal or direct replications, close replications, and conceptual replications as long as the target study is specified and published.\nStudent first authors can but do not have to request “student report” status for their submissions. For these submissions, soft review deadlines are shorter (2 weeks instead of 4 weeks) and only a response from one reviewer is required. However, adherence to TOP guidelines (see below) and reproducibility check are still required.\nFor more information, see the Submission Guidelines."
  },
  {
    "objectID": "about.html#top-guidelines",
    "href": "about.html#top-guidelines",
    "title": "About the Journal",
    "section": "TOP Guidelines",
    "text": "TOP Guidelines\nThe following table stems from the Center for Open Science. Replication Research requires level 3 adherence to Transparency and Openness Promotion (TOP) guidelines. Adherence to TOP Research Practices is checked by reviewers in a structured form that they are required to submit alongside their review. Verification Practices are organized by the journal, that is the reproducibility manager. Replication Research accepts all types of Verification Studies.\n\n\n\n\n\n\n\n\nCriterion\nLevel\nExplanation\n\n\n\n\nStudy Registration\n3\nA party independent from the authors certified that the study was registered at an appropriate time, and the registration was complete per disciplinary best-practice.\n\n\nStudy \nProtocol\n3\nA party independent from the authors certified that the study protocol was shared and complete per disciplinary best-practice.\n\n\nAnalysis \nPlan\n3\nA party independent from the authors certified that the analysis plan was shared and complete per disciplinary best-practice.\n\n\nMaterials Transparency\n3\nA party independent from the authors certified that materials were deposited and documented per disciplinary best-practice.\n\n\nData \nTransparency\n3\nA party independent from the authors certified that data were deposited with metadata per disciplinary best-practice.\n\n\nAnalytic Code \nTransparency\n3\nA party independent from the authors certified that analytic code was deposited and documented per disciplinary best-practice.\n\n\nReporting Transparency\n3\nA party independent from the authors certified that the authors adhered to the cited reporting guideline.\n\n\n\n\n\n\n\n\n\n\nVerification Practice\nDefinition\n\n\n\n\nComprehensive Reporting\nA party independent from the authors verified that the study registration, protocol, and analysis plan match the final report–and the final report acknowledges any deviations from these outputs.\n\n\nComputational Reproducibility\nA party independent from the authors verified that reported results reproduce using shared data and code.\n\n\n\n\n\n\n\n\n\n\nVerification Study Type\nDefinition\n\n\n\n\nReplication\nA study that aims to provide diagnostic evidence about claims from a prior study by repeating the original study procedures in a new sample.\n\n\nRegistered Report\nA registered study in which a study protocol and analysis plan are peer reviewed, and the study is pre-accepted by a publication outlet, before the research is undertaken.\n\n\nMultiverse\nA study that tests the research question of interest across multiple datasets arising from different, reasonable choices for processing and analyzing the same data.\n\n\nMany Analyst\nA study in which independent analysis teams conduct plausible alternative analyses of a research question on the same dataset."
  },
  {
    "objectID": "about.html#publication-process",
    "href": "about.html#publication-process",
    "title": "About the Journal",
    "section": "Publication Process",
    "text": "Publication Process"
  },
  {
    "objectID": "about.html#additional-information",
    "href": "about.html#additional-information",
    "title": "About the Journal",
    "section": "Additional Information",
    "text": "Additional Information\nISSN: —\nTop Factor: 28\nThe Nordic List: — \nDOAJ: —\nFunding: Supported by the Münster Center for Open Science, University of Münster"
  },
  {
    "objectID": "about.html#contributions-and-references",
    "href": "about.html#contributions-and-references",
    "title": "About the Journal",
    "section": "Contributions and References",
    "text": "Contributions and References\nThese guidelines are shared under a CC 4.0 by Attribution License and have been created by Lukas Röseler (Writing - first draft) and XXX (CRediT). They are loosely based on the submission guidelines from Meta Psychology (https://open.lnu.se/index.php/metapsychology/about/submissions)."
  },
  {
    "objectID": "collection.html",
    "href": "collection.html",
    "title": "Replication Collection",
    "section": "",
    "text": "This is a collection of replication research based on the FORRT Replication Database. Please note that these articles have not necessarily been peer-reviewed or published by Replication Research. This collection serves as a way to make replication research across disciplines visible. To add a replication study, please use this Google form and send an e-mail to lukas.roeseler[at]uni-muenster.de.\n\n\n\n\n\n\n\n\nLast update: 2024-09-20"
  },
  {
    "objectID": "index.html#free-to-read-free-to-publish",
    "href": "index.html#free-to-read-free-to-publish",
    "title": "REPLICATION RESEARCH",
    "section": "Free to read, free to publish",
    "text": "Free to read, free to publish\nReplication Research is a Diamond Open Access Journal with strict and entirely transparent quality control and no author processing charges. We publish close and conceptual replications as well as reproductions."
  },
  {
    "objectID": "index.html#valueing-high-quality-replication-research",
    "href": "index.html#valueing-high-quality-replication-research",
    "title": "REPLICATION RESEARCH",
    "section": "Valueing high-quality replication research",
    "text": "Valueing high-quality replication research\nReplications should be the foundation for cumulative and quantitative science but they are not. We are here to change this. If you seek to publish replication research with rigorous and transparent quality assurance in an open and accessible way, we are here for you."
  },
  {
    "objectID": "index.html#researcher-led",
    "href": "index.html#researcher-led",
    "title": "REPLICATION RESEARCH",
    "section": "Researcher-led",
    "text": "Researcher-led\nReplication Research is hosted by the University of Münster and maintained by the Münster Center for Open Science (MüCOS) and the Framework for Open and Reproducible Research Training (FORRT).\n\n\n\n\n\n\nNote\n\n\n\n&gt;&gt; The submission portal will be made available in fall 2025"
  },
  {
    "objectID": "index.html#hosts",
    "href": "index.html#hosts",
    "title": "REPLICATION RESEARCH",
    "section": "Hosts",
    "text": "Hosts"
  },
  {
    "objectID": "index.html#partners",
    "href": "index.html#partners",
    "title": "REPLICATION RESEARCH",
    "section": "Partners",
    "text": "Partners"
  },
  {
    "objectID": "review.html#transparency",
    "href": "review.html#transparency",
    "title": "Reviewer Guidelines",
    "section": "Transparency",
    "text": "Transparency\nTo make quality assurance as transparent as possible, reviews need to be signed by the reviewers and they will be published after each round of peer-review. They will be permanently linked with the submitted pre-print through a comment on PubPeer. This is regardless of whether the article is accepted, returned for revision, or rejected. PubPeer comments will be made by the journal."
  },
  {
    "objectID": "review.html#disclosures",
    "href": "review.html#disclosures",
    "title": "Reviewer Guidelines",
    "section": "Disclosures",
    "text": "Disclosures\nReviewers are asked to make a recommendation (accept, revise, reject) and to justify their decision. Reviewers need to disclose whether they reviewed the preregistration, materials, data, and code."
  },
  {
    "objectID": "review.html#reviewer-code-of-conduct",
    "href": "review.html#reviewer-code-of-conduct",
    "title": "Reviewer Guidelines",
    "section": "Reviewer code of conduct",
    "text": "Reviewer code of conduct\nReviewers are expected to provide constructive feedback. Personal attacks, coercion to cite their research, or vague criticism may lead to reviewers being blacklisted to review articles for Replication Research. Reviewers must not base their decision on the outcome, that is, acceptance/rejection due to a successful or failed replication is not considered in the editorial board’s decisions.\nReviewers must declare all potential conflicts of interest and explain if and how they are connected to the authors of the original work. Reviewers must declare use of AI (e.g., “Points 2 and 3 are based on the suggestions of ChatGTP 4”)."
  },
  {
    "objectID": "review.html#review-checklist",
    "href": "review.html#review-checklist",
    "title": "Reviewer Guidelines",
    "section": "Review checklist",
    "text": "Review checklist\n[To be incorporated into OJS]\nPlease enter your decision and justification here.\nDecision:\n[radio-button: accept, revise, reject]\nJustification / Comments for the authors:\n[open-ended]\nReview coverage:\nPlease indicate what parts of the submitted research you reviewed.\n\nmanuscript\noriginal report\nsupplemental materials (if submitted)\npreregistration\nmaterials\ndata\ncode\npush-button replicability\n\nDisclosures:\n\nI recommend a statistical expert to give feedback on the analyses.\nMy comments adhere to the reviewer code of conduct in that they are constructive and targeted at improving the manuscript.\nI have been working together with the author / one of the authors.\nI have been working together with the editor handling this submission."
  }
]